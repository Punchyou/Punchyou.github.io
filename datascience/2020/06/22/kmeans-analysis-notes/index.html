<!DOCTYPE html> <html lang=" en "><head> <meta charset="utf-8"> <title>Maria Pantsiou - Software Developer @ARM</title> <meta http-equip="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="k-means Clustering" /> <meta name="keywords" content="k-means Clustering, Maria Pantsiou, dataScience" /> <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml"> <meta content="" property="fb:app_id"> <meta content="Maria Pantsiou" property="og:site_name"> <meta content="k-means Clustering" property="og:title"> <meta content="article" property="og:type"> <meta content="k-means Clustering" property="og:description"> <meta content="/datascience/2020/06/22/kmeans-analysis-notes/" property="og:url"> <meta content="2020-06-22T09:05:23+00:00" property="article:published_time"> <meta content="/about/" property="article:author"> <meta content="dataScience" property="article:section"> <meta name="twitter:card" content="summary"> <meta name="twitter:site" content="@"> <meta name="twitter:creator" content="@"> <meta name="twitter:title" content="k-means Clustering"> <meta content="Maria Pantsiou" property="og:site_name"> <meta name="twitter:url" content="/datascience/2020/06/22/kmeans-analysis-notes/"> <meta name="twitter:description" content="devlopr-jekyll is a Jekyll Theme Built For Developers"> <link rel="stylesheet" href="/assets/css/main.css" /> <link rel="stylesheet" href="/assets/css/custom-style.css" /> <link rel="stylesheet" href="/assets/bower_components/lightgallery/dist/css/lightgallery.min.css"/> <link rel="stylesheet" href="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.css" /> <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.css"> <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch-theme-algolia.min.css"> <link rel="stylesheet" href="/assets/bower_components/bootstrap/dist/css/bootstrap.min.css" /> <link rel="stylesheet" href="/assets/bower_components/font-awesome/web-fonts-with-css/css/fontawesome-all.min.css" /> <!-- Fonts--> <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet"> <!-- Favicon --> <link rel="icon" href="/assets/img/favicon.ico" type="image/gif" sizes="16x16"> <!-- Jquery --> <script src="https://code.jquery.com/jquery-3.4.1.min.js" integrity="sha384-vk5WoKIaW/vJyUAd9n/wmopsmNhiy+L2Z+SBxGYnUkunIxVxAv/UtMOhba/xskxh" crossorigin="anonymous"></script> <!-- <script src="/assets/bower_components/jquery/dist/jquery.min.js"></script> --> <script src="/assets/bower_components/jquery.easing/jquery.easing.min.js"></script> <script src="/assets/bower_components/bootstrap/dist/js/bootstrap.bundle.min.js"></script> <script src="/assets/bower_components/jquery-mousewheel/jquery.mousewheel.min.js"></script> <script src="/assets/bower_components/lightgallery/dist/js/lightgallery-all.min.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/picturefill/3.0.2/picturefill.min.js"></script> <script src="/assets/bower_components/imagesloaded/imagesloaded.pkgd.min.js"></script> <script src="/assets/bower_components/nanobar/nanobar.min.js"></script> <script src="/assets/bower_components/typewrite/dist/typewrite.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.20.1/moment.min.js"></script> <!-- Github Button --> <script async defer src="https://buttons.github.io/buttons.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script> <script> (function (i, s, o, g, r, a, m) { i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () { (i[r].q = i[r].q || []).push(arguments) }, i[r].l = 1 * new Date(); a = s.createElement(o), m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m) })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga'); ga('create', '', 'auto'); ga('send', 'pageview'); </script> </head> <body> <div class="container-fluid"><header> <div class="col-lg-12"> <div class="row"> <nav class="navbar navbar-expand-lg fixed-top navbar-dark " id="topNav"> <!-- <a class="navbar-brand" href="#">Maria Pantsiou</a> --> <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button> <a class="navbar-brand" href="/">Maria Pantsiou</a> <div class="collapse navbar-collapse" id="navbarNav"> <ul class="navbar-nav"> <li class="nav-item"> <a class="nav-link" href="/about">About Me</a> </li> <li class="nav-item"> <a class="nav-link" href="/blog">Blog</a> </li> </ul> </div> <ul class="nav justify-content-end"> <li class="nav-item"> <a class="nav-link" id="search-icon" href="/search/"><i class="fa fa-search" aria-hidden="true"></i></a> </li> <li class="nav-item"> <input class="nav-link switch" id="theme-toggle" onclick="modeSwitcher() "type="checkbox" name="checkbox" > </li> </ul> </nav> </div> </div> </header><div class="col-lg-12"> <!-- Blog Post Breadcrumbs --><div class="col-lg-12"> <nav aria-label="breadcrumb" role="navigation"> <ol class="breadcrumb"> <li class="breadcrumb-item"> <a href="/blog"><i class="fa fa-home" aria-hidden="true"></i></a> </li> <li class="breadcrumb-item active" aria-current="page"><a href="/datascience/2020/06/22/kmeans-analysis-notes/">k-means Clustering</a></li> </ol> </nav> </div> <div class="row" id="blog-post-container"> <div class="col-lg-8 offset-md-2"><article class="card" itemscope itemtype="http://schema.org/BlogPosting"> <div class="card-header"> <!-- <h1 class="post-title" itemprop="name headline">k-means Clustering</h1> --> <h4 class="post-meta">k-means Clustering</h4> <p class="post-summary">Posted by : <img src="/assets/img/avatar.png" class="author-profile-img"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"> <span itemprop="name">Maria Pantsiou</span> </span> at <time datetime="2020-06-22 09:05:23 +0000" itemprop="datePublished">Jun 22, 2020</time> </p> <span class="disqus-comment-count" data-disqus-identifier="/datascience/2020/06/22/kmeans-analysis-notes/"></span> <div class="post-categories"> Category : <a href="/blog/categories/dataScience">dataScience</a> </div> </div> <div class="card-body" itemprop="articleBody"> <img class="card-img-top" src="/assets/img/posts/triangles_background.png" alt=""> <br/> <br/> <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], displayMath: [['$$','$$']], inlineMath: [['$','$']], }, }); </script> <p><em>I recenently did a k-means clustering analysis and along that way I explored different things someone should consider when using k-means, like how to choose <strong>the best way to determine the number</strong> of clusters or add extra features beforehand in the k-means algorithm for better clustering results. Here are my findings:</em></p> <h1 id="clustering">Clustering</h1> <p>It can be defined as the task of identifying subgroups in the data such that data points in the same subgroup (cluster) are very similar while data points in different clusters are very different. It is considered an unsupervised learning method since we don’t have the ground truth to compare the output of the clustering algorithm to the true labels to evaluate its performance. We only want to try to investigate the structure of the data by grouping the data points into distinct subgroups.</p> <h3 id="why-clustering">Why Clustering?</h3> <p>We can get a meaningful intuition of the structure of the data we’re dealing with. Also, different models can be built for different subgroups if we believe there is a wide variation in the behaviors of different subgroups.</p> <h1 id="k-means">K-means</h1> <p>The k-means is an unsupervised learning algorithm that tries to partition the dataset into K re-defined distinct non-overlapping subgroups (clusters) where each data point belongs to <strong>only one group</strong>. It tries to make the intra-cluster data points as similar as possible while also keeping the clusters as different (far) as possible. It assigns data points to a cluster such that the sum of the squared distance between the data points and the cluster’s centroid <em>(arithmetic mean of all the data points that belong to that cluster)</em> is at the minimum. The less variation we have within clusters, the more homogeneous (similar) the data points are within the same cluster.</p> <h3 id="how-it-works">How it works</h3> <ol> <li>User needs to specify the number of clusters K</li> <li>The algorithm initializes centroids by first shuffling the dataset and then randomly selecting K data points for the centroids without replacement: <ul> <li>Computes the sum of the squared distance between data points and all centroids</li> <li>Assigns each data point to the closest cluster (centroid)</li> <li>Computes the centroids for the clusters by taking the average of the all data points that belong to each cluster</li> </ul> </li> <li>Keeps iterating until there is no change to the centroids. i.e assignment of data points to clusters isn’t changing.</li> </ol> <p>The approach kmeans follows to solve the problem is called <strong>Expectation-Maximization</strong>.</p> <h3 id="implementation">Implementation</h3> <p>We will implement the kmeans algorithm on a 2D <a href="https://gist.githubusercontent.com/curran/4b59d1046d9e66f2787780ad51a1cd87/raw/9ec906b78a98cf300947a37b56cfe70d01183200/data.tsv">dataset</a> and see how it works. The data covers the waiting time between eruptions and the duration of the eruption for the Old Faithful geyser in Yellowstone National Park, Wyoming, USA. We will try to find K subgroups within the data points and group them accordingly. Below is the description of the features:</p> <ul> <li>eruptions (<code class="language-plaintext highlighter-rouge">float</code>): Eruption time in minutes.</li> <li>waiting (<code class="language-plaintext highlighter-rouge">int</code>): Waiting time to next eruption.</li> </ul> <p>With the following code, we start by importing the modules we will need, and upload and plot our data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.image</span> <span class="kn">import</span> <span class="n">imread</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span><span class="p">,</span> <span class="n">make_circles</span><span class="p">,</span> <span class="n">make_moons</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span><span class="p">,</span> <span class="n">SpectralClustering</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_samples</span><span class="p">,</span> <span class="n">silhouette_score</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="c1"># Import and clean the data
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s">"https://gist.githubusercontent.com/curran/4b59d1046d9e66f2787780ad51a1cd87/raw/9ec906b78a98cf300947a37b56cfe70d01183200/data.tsv"</span>
<span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"Eraptions"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"eruptions</span><span class="se">\t</span><span class="s">waiting"</span><span class="p">]</span><span class="o">.</span><span class="nb">str</span><span class="o">.</span><span class="nb">slice</span><span class="p">(</span><span class="n">stop</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"float"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"Twaiting"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"eruptions</span><span class="se">\t</span><span class="s">waiting"</span><span class="p">]</span><span class="o">.</span><span class="nb">str</span><span class="o">.</span><span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"int"</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">"eruptions</span><span class="se">\t</span><span class="s">waiting"</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="c1"># Plot the data
</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Eruption time in mins'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Waiting time to next eruption'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Visualization of raw data'</span><span class="p">)</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/k-means/data-plot.png" alt="data-simple-plot" width="400" height="400" /> </div> <p>The graph shows that we have 2 clusters in the data.</p> <p>Before running the k-means for 2 cluster, let’s standardise the data. We will use the <code class="language-plaintext highlighter-rouge">sklearn.preprocessing.StandardScaler</code> for the. The <code class="language-plaintext highlighter-rouge">StandardScaler</code> standardize features by removing the mean and scaling to unit variance:</p> <p>The standard score of a sample x is calculated as:</p> <script type="math/tex; mode=display">z = \frac{(x - u)}{s}</script> <p>where $u$ is the mean of the training samples (zero if <code class="language-plaintext highlighter-rouge">with_mean=False</code>) and $s$ is the standard deviation of the training samples (one if <code class="language-plaintext highlighter-rouge">with_std=False</code>).</p> <p>In our case this will be:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Standardize the data
</span><span class="n">X_std</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <p>We will now run the k-means algorithm for k=2 clusters. I’m using the <code class="language-plaintext highlighter-rouge">sklearn.cluster.KMeans</code> algorithm which performs a simple k-means clustering. Some comments about the arguments to keep in mind:</p> <ul> <li><code class="language-plaintext highlighter-rouge">n_init</code> is the number of times of running the kmeans with different centroid’s initialization. The result of the best one will be reported.</li> <li><code class="language-plaintext highlighter-rouge">tol</code> is the within-cluster variation metric used to declare convergence.</li> <li>The default of <code class="language-plaintext highlighter-rouge">init</code> is <code class="language-plaintext highlighter-rouge">k-means++"</code> which is supposed to yield a better results than just random initialization of centroids.</li> </ul> <p>Note that at this point we will be using the <code class="language-plaintext highlighter-rouge">n_clusters</code> as the number of clutsers and the <code class="language-plaintext highlighter-rouge">max_iter</code> as the maximum number of times that the k-means will recalculate the centroid position.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Run local implementation of kmeans
</span><span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">km</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_std</span><span class="p">)</span>
<span class="n">centroids</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">cluster_centers_</span>

<span class="n">ig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_std</span><span class="p">[</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_std</span><span class="p">[</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="s">'green'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'cluster 1'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_std</span><span class="p">[</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_std</span><span class="p">[</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="s">'blue'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'cluster 2'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centroids</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centroids</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s">'*'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'centroid'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Eruption time in mins'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Waiting time to next eruption'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Visualization of clustered data'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s">'bold'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s">'equal'</span><span class="p">)</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/k-means/clusters-plot.png" alt="clusters-plot" width="400" height="400" /> </div> <p>So, we have now generated a plot where the two clusters have differene colors and the centroid is represented by a red star.</p> <p>Next, we will se that different initializations of centroids may yield to different results. We will use <code class="language-plaintext highlighter-rouge">random_state</code> for random initialization 9 times and we will limit to 3 iterations to see the effect of this. The code looks like this:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_iter</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
<span class="n">centers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">):</span>
    <span class="c1"># Run local implementation of kmeans
</span>    <span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">max_iter</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">km</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_std</span><span class="p">)</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">cluster_centers_</span>
    <span class="n">centers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_std</span><span class="p">[</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_std</span><span class="p">[</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                  <span class="n">c</span><span class="o">=</span><span class="s">'green'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'cluster 1'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_std</span><span class="p">[</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_std</span><span class="p">[</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                  <span class="n">c</span><span class="o">=</span><span class="s">'blue'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'cluster 2'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centroids</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centroids</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                  <span class="n">c</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'*'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'centroid'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower right'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">f</span><span class="s">'{km.inertia_:.4f}'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s">'equal'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/k-means/k-means-randon-state.png" alt="random-state-clustering" width="700" height="700" /> </div> <h3 id="implementation-of-k-means-for-image-compression">Implementation of k-means for image compression</h3> <p>For this compression I’m using a 429x740x3 image. For each one of the 429x740 pixels location we would have 3 8-bit integers that specify the red, green, and blue intensity values (abbreviation of RGB). Our goal is to reduce the number of colors to 30 and represent (compress) the photo using those 30 colors only. To pick which colors to use, we’ll use kmeans algorithm on the image and treat every pixel as a data point. Doing so will allow us to represent the image using the 30 centroids for each pixel and would significantly reduce the size of the image by a factor of 6.</p> <p>The code is the following:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># read the image
</span><span class="n">img</span> <span class="o">=</span> <span class="n">imread</span><span class="p">(</span><span class="s">'kassandra.jpg'</span><span class="p">)</span>
<span class="n">img_size</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Reshape it to be 2-dimension
</span><span class="n">X</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">img_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">img_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">img_size</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># Run the Kmeans algorithm
</span><span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">km</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Use the centroids to compress the image
</span><span class="n">X_compressed</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="n">km</span><span class="o">.</span><span class="n">labels_</span><span class="p">]</span>
<span class="n">X_compressed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">X_compressed</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'uint8'</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>

<span class="c1"># Reshape X_recovered to have the same dimension as the original image
</span><span class="n">X_compressed</span> <span class="o">=</span> <span class="n">X_compressed</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">img_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">img_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">img_size</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># Plot the original and the compressed image next to each other
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Original Image'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_compressed</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Compressed Image with 30 colors'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/k-means/kassandra-kmeans.png" alt="kassandra-kmeans" /> </div> <p>The compressed image looks close to the original one which means we’re able to retain the majority of the characteristics of the original image. This image compression method is called <strong>lossy data compression</strong> because we can’t reconstruct the original image from the compressed image.</p> <h2 id="evaluation">Evaluation</h2> <p>When using k-means, we need to determine how many clusters we need to have beforehand and then feed that number into the algorithm. A few ways that help us find the best cluster number are following:</p> <h3 id="1-the-elbow-method">1. The Elbow method</h3> <p>This method gives us an idea on what a good k number of clusters would be based on the <strong>sum of squared distance (SSE)</strong> between data points and their assigned clusters’ centroids. We pick k at the spot where SSE starts to flatten out and forming an elbow. We’ll use the geyser dataset we first used and evaluate SSE for different values of k and see where the curve might form an elbow and flatten out. The code is the following:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Run the Kmeans algorithm and get the index of data points clusters
</span><span class="n">sse</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">list_k</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">list_k</span><span class="p">:</span>
    <span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">km</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_std</span><span class="p">)</span>
    <span class="n">sse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">km</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1"># Plot sse against k
</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">list_k</span><span class="p">,</span> <span class="n">sse</span><span class="p">,</span> <span class="s">'-o'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">r'Number of clusters *k*'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Sum of squared distance'</span><span class="p">)</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/k-means/elbow.png" alt="elbow" /> </div> <p>The graph above shows that k=2 is the bect choice.</p> <h3 id="2--the-silhouette-analysis">2. The Silhouette Analysis</h3> <p>The SA is a way to measure how close each point in a cluster is to the points in its neighboring clusters. It can be used to determine the <strong>degree of separation</strong> between clusters. Values lie in the range of [-1, 1]. A value of +1 indicates that the sample is far away from its neighboring cluster and very close to the cluster its assigned. Similarly, value of -1 indicates that the point is close to its neighboring cluster than to the cluster its assigned. A value of 0 means its at the boundary of the distance between the two cluster.</p> <h4 id="definition">Definition:</h4> <p>For an example $(i)$ in the data, lets define $a(i)$ to be the mean distance of point $(i)$ with regards to all the other points in the cluster its assigned $(A)$. We can interpret $a(i)$ as how well the point is assigned to the cluster. Smaller the value better the assignment.</p> <p>Now, let $b(i)$ is the mean distance of point $(i)$ with regards to other points to its closer neighboring cluster $(B)$. The cluster $(B)$ is the cluster to which point $(i)$ is not assigned to but its distance is closest amongst all other cluster.</p> <p>The silhouette coefficient $s(i)$ can be calculated:</p> <script type="math/tex; mode=display">s(i) = \frac{(b(i) - a(i))}{max(b(i), a(i))}</script> <p>For $s(i)$ to be close to 1, $a(i)$ has be be very small as compared to $b(i)$, i.e. $a(i) « b(i)$. This happens when $a(i)$ is very close to its assigned cluster. A large value of $b(i)$ implies its extremely far from its next closest cluster. Hence, $s(i) = 1$ indicates that the data set $(i)$ is well matched in the cluster assignment.</p> <p>Note that the definition above doesn’t tell the SA score for the entire cluster, it only idecates the sihlouatte for one data point.</p> <h4 id="mean-silhouette-score">Mean Silhouette score:</h4> <p>Mean score can be simply calculated by taking the mean of silhouette score of all the examples in the data set. This gives us one value representing the Silhouette score of the entire cluster.</p> <h4 id="why-sa">Why SA?</h4> <p>You can use SA for an un-labelled data set, which is usually the case when running k-means. Hence, <a href="https://kapilddatascience.wordpress.com/author/kapildalwani/">kapildalwani</a> prefers this over other k-means scores like V-measure, Adjusted rank Index, V-score, Homogeneity etc</p> <h4 id="examples">Examples:</h4> <p>Here are two examples of visualizing the $S$ values.</p> <div align="center"> <img src="/assets/img/posts/k-means/kmeans-silhouette.png" alt="silhouette" width="900" height="300" /> </div> <p>Each shaded area represents the $S$ score for the corresponding cluster and the red dotted line is the mean. The value is roughly around 0.7 which means the clustering is good.</p> <p>You can now see how some of the following clusters appear a smaller $S$ values, plus the are not unifonmly destributed.</p> <div align="center"> <img src="/assets/img/posts/k-means/kmeans-silhouette-failed.png" alt="silhouette-failed" width="900" height="300" /> </div> <p>The implementation of the silhouette analysis on our Geyser’s Eruptions datasets is the following:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
    
    <span class="c1"># Run the Kmeans algorithm
</span>    <span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_std</span><span class="p">)</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">cluster_centers_</span>

    <span class="c1"># Get silhouette samples
</span>    <span class="n">silhouette_vals</span> <span class="o">=</span> <span class="n">silhouette_samples</span><span class="p">(</span><span class="n">X_std</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

    <span class="c1"># Silhouette plot
</span>    <span class="n">y_ticks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_lower</span><span class="p">,</span> <span class="n">y_upper</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)):</span>
        <span class="n">cluster_silhouette_vals</span> <span class="o">=</span> <span class="n">silhouette_vals</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">cluster</span><span class="p">]</span>
        <span class="n">cluster_silhouette_vals</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
        <span class="n">y_upper</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cluster_silhouette_vals</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">y_lower</span><span class="p">,</span> <span class="n">y_upper</span><span class="p">),</span> <span class="n">cluster_silhouette_vals</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'none'</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">0.03</span><span class="p">,</span> <span class="p">(</span><span class="n">y_lower</span> <span class="o">+</span> <span class="n">y_upper</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">y_lower</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cluster_silhouette_vals</span><span class="p">)</span>

    <span class="c1"># Get the average silhouette score and plot it
</span>    <span class="n">avg_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">silhouette_vals</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">avg_score</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'green'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Silhouette coefficient values'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Cluster labels'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Silhouette plot for the various clusters'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">);</span>
    
    <span class="c1"># Scatter plot of data colored with labels
</span>    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_std</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_std</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centroids</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centroids</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s">'*'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Eruption time in mins'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Waiting time to next eruption'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Visualization of clustered data'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s">'equal'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">f</span><span class="s">'Silhouette analysis using k = {k}'</span><span class="p">,</span>
                 <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s">'semibold'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/k-means/silhouette1.png" alt="silhouette1" width="700" height="300" /> </div> <div align="center"> <img src="/assets/img/posts/k-means/silhouette2.png" alt="silhouette2" width="700" height="300" /> </div> <div align="center"> <img src="/assets/img/posts/k-means/silhouette3.png" alt="silhouette" width="700" height="300" /> </div> <p>As the above plots shows, <code class="language-plaintext highlighter-rouge">n_clusters=2</code> has the best average silhouette score of around 0.75 and all clusters being above the average shows that it is actually a good choice. Also, the thickness of the silhouette plot gives an indication of how big each cluster is. The plot shows that cluster 1 has almost double the samples than cluster 2. However, as we increased <code class="language-plaintext highlighter-rouge">n_clusters</code> to 3 and 4, the average silhouette score decreased dramatically to around 0.48 and 0.39 respectively. Moreover, the thickness of silhouette plot started showing wide fluctuations. The bottom line is: Good <code class="language-plaintext highlighter-rouge">n_clusters</code> will have a well above 0.5 silhouette average score as well as all of the clusters have higher than the average score.</p> <h4 id="some-notes-on-the-sihlouette-analysis">Some notes on the Sihlouette Analysis:</h4> <ol> <li>The mean $S$ value should be as close to 1 as possible</li> <li>The plot of each cluster should be above the mean $S$ value as much as possible. Any plot region below the mean value is not desirable</li> <li>The width of the plot should be as uniform as possible</li> </ol> <h2 id="additional-implementation-of-k-means">Additional Implementation of K-means</h2> <h3 id="k-means-with-multiple-features">K-means With Multiple Features</h3> <p>How about clustering based on more than one feature? The k-means clustering happens in n-dimensional space where $n$ is the number of features. The number of dimensions in the vector of each sample would change and there is no need to change algorithm or approach.</p> <p>The code looks pretty much like the implementation mentioned above, except that the input of the algorithm can now be a dataframe with two or more columns in it. See an example snipet below:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># prepare the datasets
</span><span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Feat_1'</span><span class="p">,</span> <span class="s">'Feat_2'</span><span class="p">,</span> <span class="s">'Feat_3'</span><span class="p">,</span> <span class="s">'Feat_4'</span><span class="p">])</span>

<span class="c1"># run k-means
</span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s">'Feat_1'</span><span class="p">,</span> <span class="s">'Feat_2'</span><span class="p">,</span> <span class="s">'Feat_3'</span><span class="p">,</span> <span class="s">'Feat_4'</span><span class="p">]])</span>

<span class="n">df</span><span class="p">[</span><span class="s">'Cluster'</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>

<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</code></pre></div></div> <p>You might also want to apply PCA or any other dimentionality reduction method after the clustering for a better visualization of the multiple features.</p> <p><em>sources:</em></p> <ol> <li><a href="https://kapilddatascience.wordpress.com/2015/11/10/using-silhouette-analysis-for-selecting-the-number-of-cluster-for-k-means-clustering/">Using Silhouette analysis for selecting the number of cluster for K-means clustering (Part 2)</a> by <a href="https://kapilddatascience.wordpress.com/author/kapildalwani/">kapildalwani</a></li> <li><a href="https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a">K-means Clustering: Algorithm, Applications, Evaluation Methods, and Drawbacks</a> by <a href="https://towardsdatascience.com/@ImadPhd">Imad Dabbura</a></li> <li><a href="https://stackoverflow.com/questions/54861453/how-to-use-k-means-clustering-for-more-features/54864391">How to use k-means clustering for more features</a></li> </ol> </div> <div id="disqus_thread"></div> </article> <script> var disqus_config = function () { this.page.url = "/datascience/2020/06/22/kmeans-analysis-notes/"; /* Replace PAGE_URL with your page's canonical URL variable */ this.page.identifier = "/datascience/2020/06/22/kmeans-analysis-notes"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */ }; (function () { /* DON'T EDIT BELOW THIS LINE */ var d = document, s = d.createElement('script'); s.src = 'https://.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a> </noscript></div> </div> <!-- End of row--> <div class="row"> <div class="col-md-4"> <div class="card"> <div class="card-header"> About </div> <div class="card-body"> <!-- Your Bio --> <p class="author_bio"> Hello, My Name is Maria.</p> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Categories </div> <div class="card-body text-dark"> <div id="#guides"></div> <li class="tag-head"> <a href="/blog/categories/guides">guides</a> </li> <a name="guides"></a> <div id="#dataScience"></div> <li class="tag-head"> <a href="/blog/categories/dataScience">dataScience</a> </li> <a name="dataScience"></a> <div id="#devops"></div> <li class="tag-head"> <a href="/blog/categories/devops">devops</a> </li> <a name="devops"></a> <div id="#resources"></div> <li class="tag-head"> <a href="/blog/categories/resources">resources</a> </li> <a name="resources"></a> <div id="#AI"></div> <li class="tag-head"> <a href="/blog/categories/AI">AI</a> </li> <a name="AI"></a> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Useful Links </div> <div class="card-body text-dark"> <li > <a href="/about">About Me</a> </li> <li > <a href="/blog">Blog</a> </li> </div> </div> </div> </div> </div> </div> <footer> <p> Powered by<a href="https://github.com/sujaykundu777/devlopr-jekyll"> devlopr jekyll</a>. Hosted at <a href="https://pages.github.com">Github</a>. Subscribe via <a href=" /feed.xml ">RSS</a> </p> </footer> </div> <script> var options = { classname: 'my-class', id: 'my-id' }; var nanobar = new Nanobar( options ); nanobar.go( 30 ); nanobar.go( 76 ); nanobar.go(100); </script> <div hidden id="snipcart" data-api-key="Y2I1NTAyNWYtMTNkMy00ODg0LWE4NDItNTZhYzUxNzJkZTI5NjM3MDI4NTUzNzYyMjQ4NzU0"></div> <script src="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.js" defer></script> <script src="/assets/js/mode-switcher.js"></script> </body> </html>
