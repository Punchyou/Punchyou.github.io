<!DOCTYPE html> <html lang=" en "><head> <meta charset="utf-8"> <title>Maria Pantsiou - Software Developer @ARM</title> <meta http-equip="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="kmeans Vs DBSCAN" /> <meta name="keywords" content="kmeans Vs DBSCAN, Maria Pantsiou, dataScience" /> <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml"> <meta content="" property="fb:app_id"> <meta content="Maria Pantsiou" property="og:site_name"> <meta content="kmeans Vs DBSCAN" property="og:title"> <meta content="article" property="og:type"> <meta content="kmeans Vs DBSCAN" property="og:description"> <meta content="/datascience/2020/06/25/keams-vs-dbscan/" property="og:url"> <meta content="2020-06-25T09:05:23+00:00" property="article:published_time"> <meta content="/about/" property="article:author"> <meta content="dataScience" property="article:section"> <meta name="twitter:card" content="summary"> <meta name="twitter:site" content="@"> <meta name="twitter:creator" content="@"> <meta name="twitter:title" content="kmeans Vs DBSCAN"> <meta content="Maria Pantsiou" property="og:site_name"> <meta name="twitter:url" content="/datascience/2020/06/25/keams-vs-dbscan/"> <meta name="twitter:description" content="devlopr-jekyll is a Jekyll Theme Built For Developers"> <link rel="stylesheet" href="/assets/css/main.css" /> <link rel="stylesheet" href="/assets/css/custom-style.css" /> <link rel="stylesheet" href="/assets/bower_components/lightgallery/dist/css/lightgallery.min.css"/> <link rel="stylesheet" href="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.css" /> <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.css"> <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch-theme-algolia.min.css"> <link rel="stylesheet" href="/assets/bower_components/bootstrap/dist/css/bootstrap.min.css" /> <link rel="stylesheet" href="/assets/bower_components/font-awesome/web-fonts-with-css/css/fontawesome-all.min.css" /> <!-- Fonts--> <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet"> <!-- Favicon --> <link rel="icon" href="/assets/img/favicon.ico" type="image/gif" sizes="16x16"> <!-- Jquery --> <script src="https://code.jquery.com/jquery-3.4.1.min.js" integrity="sha384-vk5WoKIaW/vJyUAd9n/wmopsmNhiy+L2Z+SBxGYnUkunIxVxAv/UtMOhba/xskxh" crossorigin="anonymous"></script> <!-- <script src="/assets/bower_components/jquery/dist/jquery.min.js"></script> --> <script src="/assets/bower_components/jquery.easing/jquery.easing.min.js"></script> <script src="/assets/bower_components/bootstrap/dist/js/bootstrap.bundle.min.js"></script> <script src="/assets/bower_components/jquery-mousewheel/jquery.mousewheel.min.js"></script> <script src="/assets/bower_components/lightgallery/dist/js/lightgallery-all.min.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/picturefill/3.0.2/picturefill.min.js"></script> <script src="/assets/bower_components/imagesloaded/imagesloaded.pkgd.min.js"></script> <script src="/assets/bower_components/nanobar/nanobar.min.js"></script> <script src="/assets/bower_components/typewrite/dist/typewrite.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.20.1/moment.min.js"></script> <!-- Github Button --> <script async defer src="https://buttons.github.io/buttons.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script> <script> (function (i, s, o, g, r, a, m) { i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () { (i[r].q = i[r].q || []).push(arguments) }, i[r].l = 1 * new Date(); a = s.createElement(o), m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m) })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga'); ga('create', '', 'auto'); ga('send', 'pageview'); </script> </head> <body> <div class="container-fluid"><header> <div class="col-lg-12"> <div class="row"> <nav class="navbar navbar-expand-lg fixed-top navbar-dark " id="topNav"> <!-- <a class="navbar-brand" href="#">Maria Pantsiou</a> --> <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button> <a class="navbar-brand" href="/">Maria Pantsiou</a> <div class="collapse navbar-collapse" id="navbarNav"> <ul class="navbar-nav"> <li class="nav-item"> <a class="nav-link" href="/about">About Me</a> </li> <li class="nav-item"> <a class="nav-link" href="/blog">Blog</a> </li> </ul> </div> <ul class="nav justify-content-end"> <li class="nav-item"> <a class="nav-link" id="search-icon" href="/search/"><i class="fa fa-search" aria-hidden="true"></i></a> </li> <li class="nav-item"> <input class="nav-link switch" id="theme-toggle" onclick="modeSwitcher() "type="checkbox" name="checkbox" > </li> </ul> </nav> </div> </div> </header><div class="col-lg-12"> <!-- Blog Post Breadcrumbs --><div class="col-lg-12"> <nav aria-label="breadcrumb" role="navigation"> <ol class="breadcrumb"> <li class="breadcrumb-item"> <a href="/blog"><i class="fa fa-home" aria-hidden="true"></i></a> </li> <li class="breadcrumb-item active" aria-current="page"><a href="/datascience/2020/06/25/keams-vs-dbscan/">kmeans Vs DBSCAN</a></li> </ol> </nav> </div> <div class="row" id="blog-post-container"> <div class="col-lg-8 offset-md-2"><article class="card" itemscope itemtype="http://schema.org/BlogPosting"> <div class="card-header"> <!-- <h1 class="post-title" itemprop="name headline">kmeans Vs DBSCAN</h1> --> <h4 class="post-meta">kmeans Vs DBSCAN</h4> <p class="post-summary">Posted by : <img src="/assets/img/avatar.png" class="author-profile-img"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"> <span itemprop="name">Maria Pantsiou</span> </span> at <time datetime="2020-06-25 09:05:23 +0000" itemprop="datePublished">Jun 25, 2020</time> </p> <span class="disqus-comment-count" data-disqus-identifier="/datascience/2020/06/25/keams-vs-dbscan/"></span> <div class="post-categories"> Category : <a href="/blog/categories/dataScience">dataScience</a> </div> </div> <div class="card-body" itemprop="articleBody"> <img class="card-img-top" src="/assets/img/posts/" alt=""> <br/> <br/> <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], displayMath: [['$$','$$']], inlineMath: [['$','$']], }, }); </script> <h3 id="dbscan-vs-k-means">DBSCAN vs k-means</h3> <p><em>After completing some work with k-means, I needed to do a deeper analysis and find alternative ways of clustering based on more than two features as input. Here I’m presenting interesting things I found on DBSCAN with regards to its difference from k-means.</em></p> <h2 id="k-means-and-where-it-can-fail">K-means and Where It Can Fail</h2> <p>I’ve written another article on k-means, so you can find more information and implementations <a href="www.link-to-the-article.com">here</a>.</p> <p>Briefly, kmeans clustering does the following:</p> <ol> <li>Tries to find cluster centers that are representative of certain regions of the data</li> <li>Alternates between two steps: assigning each data point to the closest cluster center, and then setting each cluster center as the mean of the data points that are assigned to it</li> <li>The algorithm is finished when the assignment of instances to clusters no longer changes</li> </ol> <h3 id="an-issue-with-k-means">An issue with k-means</h3> <p>One issue with k-means clustering is that it assumes that all directions are equally important for each cluster. This is usually not a big problem, unless we come across with some oddly shape data.</p> <p>We can generate some data that k-means won’t be able to handle correctly:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="c1"># generate some random cluster data
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">170</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">centers</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">74</span><span class="p">)</span>

<span class="c1"># transform the data to be stretched
</span><span class="n">transformation</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">transformation</span><span class="p">)</span>

<span class="c1"># plotting
</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Feature 0"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Feature 1"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <p>We have arguably 5 defined clusters with a stretched diagonal shape.</p> <p>Let’s apply k-means clustering:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># cluster the data into five clusters
</span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="c1"># plot the cluster assignments and cluster centers
</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"plasma"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>   
            <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">marker</span><span class="o">=</span><span class="s">'^'</span><span class="p">,</span> 
            <span class="n">c</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> 
            <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
            <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s">"plasma"</span><span class="p">)</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Feature 0"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Feature 1"</span><span class="p">)</span>
</code></pre></div></div> <p>What we can see here is that k-means has been able to correctly detect the clusters at the middle and bottom, while presenting trouble with the clusters at the top, which are very close to each other. The <a href="https://www.oreilly.com/library/view/introduction-to-machine/9781449369880/">Introduction to Machine Leaning with Python</a> says <em>“these groups are stretched toward the diagonal. As k-means only considers the distance to the nearest cluster center, it can’t handle this kind of data”</em>.</p> <h2 id="dbscan">DBSCAN</h2> <p>DBSCAN is an unsupervised machine learning algorithm to classify unlabeled data. DBSCAN is very weel suited for problems with:</p> <ol> <li>Minimal domain knowledge to determine the input parameters (i.e. K in k-means and Dmin in hierarchical clustering)</li> <li>Discovery of clusters with arbitrary shapes</li> <li>Good efficiency on large databases</li> </ol> <p>Find more in the original paper <a href="http://www2.cs.uh.edu/~ceick/7363/Papers/dbscan.pdf">here</a>.</p> <p>Briefly, DBSCAN:</p> <ol> <li>Stands for “density based spatial clustering of applications with noise”</li> <li>Does not require the user to set the number of clusters a priori</li> <li>Can capture clusters of complex shapes</li> <li>Can identify points that are not part of any cluster (<strong>very useful as outliers detector</strong>)</li> <li>Is somewhat slower than agglomerative clustering and k-means, but still scales to relatively large datasets</li> <li>Works by identifying points that are in crowded regions of the feature space, where many data points are close together (dense regions in feature space)</li> <li><strong>Is very sensitive to scale</strong> since epsilon is a fixed value for the maximum distance between two points.</li> </ol> <h3 id="the-algorithm">The Algorithm</h3> <h4 id="main-parameters">Main parameters</h4> <ol> <li><code class="language-plaintext highlighter-rouge">eps</code> ($epsilon$): Two points are considered neighbors if the distance between the two points is below the threshold epsilon.</li> <li><code class="language-plaintext highlighter-rouge">min_samples</code>: The minimum number of neighbors a given point should have in order to be classified as a core point. <strong>The point itself is included in the minimum number of samples</strong>.</li> <li><code class="language-plaintext highlighter-rouge">metric</code>: An additional parameter to use when calculating distance between instances in a feature array (i.e. euclidean distance)</li> </ol> <p>The algorithm works by computing the distance between every point and all other points. We then place the points into one of three categories.</p> <h4 id="terminology">Terminology</h4> <p><strong>Core point</strong>: A point with at least <code class="language-plaintext highlighter-rouge">min_samples</code> points whose distance with respect to the point is below the threshold defined by epsilon.</p> <p><strong>Border point</strong>: A point that isn’t in close proximity to at least <code class="language-plaintext highlighter-rouge">min_samples</code> points but is close enough to one or more core point. Border points are included in the cluster of the closest core point.</p> <p><strong>Noise point</strong>: Points that aren’t close enough to core points to be considered border points. Noise points are ignored. That is to say, they aren’t part of any cluster.</p> <h3 id="implementation">Implementation</h3> <p>Starting by importing the necessary modules:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="nb">set</span><span class="p">()</span>
</code></pre></div></div> <p>We will use the <code class="language-plaintext highlighter-rouge">sklearn.datasets.make_blobs</code> module to create the datam where we can see the clusters:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># make the dataset
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.60</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/dbscan_vs_kmeans/blobs_scatter.png" alt="blobs_scatter" width="500" height="300" /> </div> <p>The next step is to find the right values for the <code class="language-plaintext highlighter-rouge">min_sample</code> and <a href="https://iopscience.iop.org/article/10.1088/1755-1315/31/1/012012/pdf"><code class="language-plaintext highlighter-rouge">eps</code></a> parameters, before running the DBSCAN. We can find a suitable value for epsilon by calculating the distance to the nearest n points for each point, sorting and plotting the results. Then we look to see where the change is most pronounced (think of the angle between your arm and forearm) and select that as epsilon. We can do that by using the <code class="language-plaintext highlighter-rouge">sklearn.neighbors.NearestNeighbors</code>. The kneighbors method returns two arrays, one which contains the distance to the closest <code class="language-plaintext highlighter-rouge">n_neighbors</code> points and the other which contains the index for each of those points.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># find the all distances between all points
</span><span class="n">neigh</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">nbrs</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">distances</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">nbrs</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/dbscan_vs_kmeans/distances.png" alt="blobs_scatter" width="300" height="600" /> <img src="/assets/img/posts/dbscan_vs_kmeans/indices.png" alt="blobs_scatter" width="200" height="600" /> </div> <p>Sorting and plotting the distances and:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># sort and plot the disctances to find the best eps parameters
</span><span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">distances</span> <span class="o">=</span> <span class="n">distances</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/dbscan_vs_kmeans/distances_plot.png" alt="blobs_scatter" width="500" height="300" /> </div> <p>We see that the optimal <code class="language-plaintext highlighter-rouge">eps</code> (distance) is approximatelly <code class="language-plaintext highlighter-rouge">0.3</code>. we can set <code class="language-plaintext highlighter-rouge">min_samples</code> to <code class="language-plaintext highlighter-rouge">5</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># run the DBSCAN algorithm
</span><span class="n">m</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></div> <p>We can now see the clusters by running:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clusters</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">labels_</span>
</code></pre></div></div> <p>Mapping each cluster to a color using the <code class="language-plaintext highlighter-rouge">numpy.vectorize</code> module:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># map each cluster to a color and plot
</span><span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'royalblue'</span><span class="p">,</span> <span class="s">'maroon'</span><span class="p">,</span> <span class="s">'forestgreen'</span><span class="p">,</span> <span class="s">'mediumorchid'</span><span class="p">,</span> <span class="s">'tan'</span><span class="p">,</span> <span class="s">'deeppink'</span><span class="p">,</span> <span class="s">'olive'</span><span class="p">,</span> <span class="s">'goldenrod'</span><span class="p">,</span> <span class="s">'lightcyan'</span><span class="p">,</span> <span class="s">'navy'</span><span class="p">]</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">colors</span><span class="p">[</span><span class="n">x</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">vectorizer</span><span class="p">(</span><span class="n">clusters</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/dbscan_vs_kmeans/clusters.png" alt="blobs_scatter" width="500" height="300" /> </div> <p>The model classified the densely populated areas. The dark blue points were categorized as noise.</p> <h3 id="second-implementation---kmeans-and-dbscan-in-the-same-dataset">Second Implementation - kmeans and DBSCAN in the same dataset</h3> <p>Here we dive stright into the code:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span><span class="p">,</span> <span class="n">DBSCAN</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.cluster</span> <span class="kn">import</span> <span class="n">adjusted_rand_score</span>

<span class="c1"># make and plot dataset
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">170</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">centers</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Feature 0"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Feature 1"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/dbscan_vs_kmeans/blobs2.png" alt="blobs2" width="500" height="300" /> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># transform the data by stretching and plot
</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">74</span><span class="p">)</span>
<span class="n">transformation</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">transformation</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Feature 0"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Feature 1"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/dbscan_vs_kmeans/blobs_stretched.png" alt="blobs2" width="500" height="300" /> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#apply k-means
</span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="c1"># plot the cluster assignments and cluster centers
</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"plasma"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>   
            <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">marker</span><span class="o">=</span><span class="s">'^'</span><span class="p">,</span> 
            <span class="n">c</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> 
            <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
            <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s">"plasma"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Feature 0"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Feature 1"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/dbscan_vs_kmeans/kmeans2.png" alt="kmeans2" width="500" height="300" /> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#apply DBSCAN
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="c1"># cluster the data into five clusters
</span><span class="n">dbscan</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.123</span><span class="p">,</span> <span class="n">min_samples</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">dbscan</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span><span class="c1"># plot the cluster assignments
</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">clusters</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"plasma"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Feature 0"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Feature 1"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <div align="center"> <img src="/assets/img/posts/dbscan_vs_kmeans/dbscan2.png" alt="dbscan2" width="500" height="300" /> </div> <h4 id="important-points">Important points</h4> <ol> <li>The parameter <code class="language-plaintext highlighter-rouge">eps</code> is somewhat more important, as it determines what it means for points to be close. Setting eps to be very small will mean that no points are core samples, and may lead to all points being labeled as noise. Setting eps to be very large will result in all points forming a single cluster.</li> <li>While DBSCAN doesn’t require setting the number of clusters explicitly, setting eps implicitly controls how many clusters will be found.</li> <li>Finding a good setting for eps is sometimes easier after scaling the data, as using these scaling techniques will ensure that all features have similar ranges.</li> </ol> <h2 id="evaluation">Evaluation</h2> <p>We can measure the performance of our algorithms using <code class="language-plaintext highlighter-rouge">adjusted_rand_score</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#k-means performance:
</span><span class="k">print</span><span class="p">(</span><span class="s">"ARI ="</span><span class="p">,</span> <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">ARI = 0.76</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#DBSCAN performance:
</span><span class="k">print</span><span class="p">(</span><span class="s">"ARI ="</span><span class="p">,</span> <span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span><span class="o">.</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">ARI = 0.99</code></p> <p>sources:</p> <ol> <li><a href="https://towardsdatascience.com/dbscan-clustering-for-data-shapes-k-means-cant-handle-well-in-python-6be89af4e6ea">DBSCAN clustering for data shapes k-means can’t handle well</a> by <a href="https://towardsdatascience.com/@gabrielpierobon">Gabriel Pierobon</a></li> <li><a href="https://towardsdatascience.com/machine-learning-clustering-dbscan-determine-the-optimal-value-for-epsilon-eps-python-example-3100091cfbc">DBSCAN Python Example: The Optimal Value For Epsilon (EPS)</a> by <a href="https://towardsdatascience.com/@corymaklin">Cory Maklin</a></li> <li><a href="https://www.oreilly.com/library/view/introduction-to-machine/9781449369880/">Introduction to Machine Leaning with Python</a> by Andreas C. Müller, Sarah Guido</li> </ol> </div> <div id="disqus_thread"></div> </article> <script> var disqus_config = function () { this.page.url = "/datascience/2020/06/25/keams-vs-dbscan/"; /* Replace PAGE_URL with your page's canonical URL variable */ this.page.identifier = "/datascience/2020/06/25/keams-vs-dbscan"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */ }; (function () { /* DON'T EDIT BELOW THIS LINE */ var d = document, s = d.createElement('script'); s.src = 'https://.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a> </noscript></div> </div> <!-- End of row--> <div class="row"> <div class="col-md-4"> <div class="card"> <div class="card-header"> About </div> <div class="card-body"> <!-- Your Bio --> <p class="author_bio"> Hello, My Name is Maria.</p> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Categories </div> <div class="card-body text-dark"> <div id="#guides"></div> <li class="tag-head"> <a href="/blog/categories/guides">guides</a> </li> <a name="guides"></a> <div id="#dataScience"></div> <li class="tag-head"> <a href="/blog/categories/dataScience">dataScience</a> </li> <a name="dataScience"></a> <div id="#devops"></div> <li class="tag-head"> <a href="/blog/categories/devops">devops</a> </li> <a name="devops"></a> <div id="#resources"></div> <li class="tag-head"> <a href="/blog/categories/resources">resources</a> </li> <a name="resources"></a> <div id="#AI"></div> <li class="tag-head"> <a href="/blog/categories/AI">AI</a> </li> <a name="AI"></a> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Useful Links </div> <div class="card-body text-dark"> <li > <a href="/about">About Me</a> </li> <li > <a href="/blog">Blog</a> </li> </div> </div> </div> </div> </div> </div> <footer> <p> Powered by<a href="https://github.com/sujaykundu777/devlopr-jekyll"> devlopr jekyll</a>. Hosted at <a href="https://pages.github.com">Github</a>. Subscribe via <a href=" /feed.xml ">RSS</a> </p> </footer> </div> <script> var options = { classname: 'my-class', id: 'my-id' }; var nanobar = new Nanobar( options ); nanobar.go( 30 ); nanobar.go( 76 ); nanobar.go(100); </script> <div hidden id="snipcart" data-api-key="Y2I1NTAyNWYtMTNkMy00ODg0LWE4NDItNTZhYzUxNzJkZTI5NjM3MDI4NTUzNzYyMjQ4NzU0"></div> <script src="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.js" defer></script> <script src="/assets/js/mode-switcher.js"></script> </body> </html>
