<!DOCTYPE html> <html lang=" en "><head> <meta charset="utf-8"> <title>Maria Pantsiou - Software Developer @ARM</title> <meta http-equip="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="Machine Learning Case Studies" /> <meta name="keywords" content="Machine Learning Case Studies, Maria Pantsiou, AI" /> <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml"> <meta content="" property="fb:app_id"> <meta content="Maria Pantsiou" property="og:site_name"> <meta content="Machine Learning Case Studies" property="og:title"> <meta content="article" property="og:type"> <meta content="Machine Learning Case Studies" property="og:description"> <meta content="/ai/2021/02/24/machine-learning-cases/" property="og:url"> <meta content="2021-02-24T09:05:23+00:00" property="article:published_time"> <meta content="/about/" property="article:author"> <meta content="AI" property="article:section"> <meta name="twitter:card" content="summary"> <meta name="twitter:site" content="@"> <meta name="twitter:creator" content="@"> <meta name="twitter:title" content="Machine Learning Case Studies"> <meta content="Maria Pantsiou" property="og:site_name"> <meta name="twitter:url" content="/ai/2021/02/24/machine-learning-cases/"> <meta name="twitter:description" content="devlopr-jekyll is a Jekyll Theme Built For Developers"> <link rel="stylesheet" href="/assets/css/main.css" /> <link rel="stylesheet" href="/assets/css/custom-style.css" /> <link rel="stylesheet" href="/assets/bower_components/lightgallery/dist/css/lightgallery.min.css"/> <link rel="stylesheet" href="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.css" /> <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.css"> <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch-theme-algolia.min.css"> <link rel="stylesheet" href="/assets/bower_components/bootstrap/dist/css/bootstrap.min.css" /> <link rel="stylesheet" href="/assets/bower_components/font-awesome/web-fonts-with-css/css/fontawesome-all.min.css" /> <!-- Fonts--> <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet"> <!-- Favicon --> <link rel="icon" href="/assets/img/favicon.ico" type="image/gif" sizes="16x16"> <!-- Jquery --> <script src="https://code.jquery.com/jquery-3.4.1.min.js" integrity="sha384-vk5WoKIaW/vJyUAd9n/wmopsmNhiy+L2Z+SBxGYnUkunIxVxAv/UtMOhba/xskxh" crossorigin="anonymous"></script> <!-- <script src="/assets/bower_components/jquery/dist/jquery.min.js"></script> --> <script src="/assets/bower_components/jquery.easing/jquery.easing.min.js"></script> <script src="/assets/bower_components/bootstrap/dist/js/bootstrap.bundle.min.js"></script> <script src="/assets/bower_components/jquery-mousewheel/jquery.mousewheel.min.js"></script> <script src="/assets/bower_components/lightgallery/dist/js/lightgallery-all.min.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/picturefill/3.0.2/picturefill.min.js"></script> <script src="/assets/bower_components/imagesloaded/imagesloaded.pkgd.min.js"></script> <script src="/assets/bower_components/nanobar/nanobar.min.js"></script> <script src="/assets/bower_components/typewrite/dist/typewrite.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.6.0/dist/instantsearch.min.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.20.1/moment.min.js"></script> <!-- Github Button --> <script async defer src="https://buttons.github.io/buttons.js"></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script> <script> (function (i, s, o, g, r, a, m) { i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () { (i[r].q = i[r].q || []).push(arguments) }, i[r].l = 1 * new Date(); a = s.createElement(o), m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m) })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga'); ga('create', '', 'auto'); ga('send', 'pageview'); </script> </head> <body> <div class="container-fluid"><header> <div class="col-lg-12"> <div class="row"> <nav class="navbar navbar-expand-lg fixed-top navbar-dark " id="topNav"> <!-- <a class="navbar-brand" href="#">Maria Pantsiou</a> --> <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button> <a class="navbar-brand" href="/">Maria Pantsiou</a> <div class="collapse navbar-collapse" id="navbarNav"> <ul class="navbar-nav"> <li class="nav-item"> <a class="nav-link" href="/about">About Me</a> </li> <li class="nav-item"> <a class="nav-link" href="/blog">Blog</a> </li> </ul> </div> <ul class="nav justify-content-end"> <li class="nav-item"> <a class="nav-link" id="search-icon" href="/search/"><i class="fa fa-search" aria-hidden="true"></i></a> </li> <li class="nav-item"> <input class="nav-link switch" id="theme-toggle" onclick="modeSwitcher() "type="checkbox" name="checkbox" > </li> </ul> </nav> </div> </div> </header><div class="col-lg-12"> <!-- Blog Post Breadcrumbs --><div class="col-lg-12"> <nav aria-label="breadcrumb" role="navigation"> <ol class="breadcrumb"> <li class="breadcrumb-item"> <a href="/blog"><i class="fa fa-home" aria-hidden="true"></i></a> </li> <li class="breadcrumb-item active" aria-current="page"><a href="/ai/2021/02/24/machine-learning-cases/">Machine Learning Case Studies</a></li> </ol> </nav> </div> <div class="row" id="blog-post-container"> <div class="col-lg-8 offset-md-2"><article class="card" itemscope itemtype="http://schema.org/BlogPosting"> <div class="card-header"> <!-- <h1 class="post-title" itemprop="name headline">Machine Learning Case Studies</h1> --> <h4 class="post-meta">Machine Learning Case Studies</h4> <p class="post-summary">Posted by : <img src="/assets/img/avatar.png" class="author-profile-img"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"> <span itemprop="name">Maria Pantsiou</span> </span> at <time datetime="2021-02-24 09:05:23 +0000" itemprop="datePublished">Feb 24, 2021</time> </p> <span class="disqus-comment-count" data-disqus-identifier="/ai/2021/02/24/machine-learning-cases/"></span> <div class="post-categories"> Category : <a href="/blog/categories/AI">AI</a> </div> </div> <div class="card-body" itemprop="articleBody"> <img class="card-img-top" src="/assets/img/posts/blue_light_cube2.png" alt=""> <br/> <br/> <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], displayMath: [['$$','$$']], inlineMath: [['$','$']], }, }); </script> <h1 id="machine-learning-case-studies">Machine Learning Case Studies</h1> <h2 id="population-segmentation">Population Segmentation</h2> <p>Thie is a classi clustering problem, that can be completed with methods like k-means (for clustering) and PCA (for dimentionality reduction, before clustering). To learn more abou k-means, you can check the articles <a href="https://punchyou.github.io/datascience/2020/06/22/kmeans-analysis-notes/#/">k-means Clustering</a> and <a href="https://punchyou.github.io/datascience/2020/06/25/keams-vs-dbscan/#/">k-means vs DBSCAN</a>.</p> <h3 id="dimentionality-reduction-with-pca-exqmple">Dimentionality Reduction with PCA exqmple</h3> <p>If we have too many dimentions in our data, we would probably need to perform some kind od dimentinoality reduction. We can find the first x principle components, depends on how many dimentions we want to end up with, that explain the (most part of the) variance of the data. Then we can project all the datapoints on that surface.</p> <p>The following are examples derived by the notebook you can find <a href="https://github.com/Punchyou/ML_SageMaker_Studies/blob/master/Population_Segmentation/Pop_Segmentation_Solution.ipynb">here</a>.</p> <p>To use data already stored in AWS (S3 bucket) we can use:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s3_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s">'s3'</span><span class="p">)</span>
<span class="n">bucket_name</span> <span class="o">=</span> <span class="s">'aws-bucket-name'</span>

<span class="c1"># list objects in that bucket
</span><span class="n">obj_list</span> <span class="o">=</span> <span class="n">s3_client</span><span class="o">.</span><span class="n">list_objects</span><span class="p">(</span><span class="n">Bucket</span><span class="o">=</span><span class="n">bucket_name</span><span class="p">)</span>

<span class="c1"># print all objects
</span><span class="n">files</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">contents</span> <span class="ow">in</span> <span class="n">obj_list</span><span class="p">[</span><span class="s">'Contents'</span><span class="p">]:</span>
	<span class="n">files</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">contents</span><span class="p">[</span><span class="s">'Key'</span><span class="p">])</span>

<span class="c1"># I want to get the first file
</span><span class="n">files_name</span> <span class="o">=</span> <span class="n">files</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">data_object</span> <span class="o">=</span> <span class="n">s3_client</span><span class="o">.</span><span class="n">get_object</span><span class="p">(</span><span class="n">Bucket</span><span class="o">=</span><span class="n">bucket_name</span><span class="p">,</span> <span class="n">Key</span><span class="o">=</span><span class="n">file_name</span><span class="p">)</span>
<span class="n">data_object</span> <span class="c1"># Assume 'Body' is a stream, and file format is csv
</span>
<span class="c1"># the streaming data is what we want from that object
</span><span class="n">data_body</span> <span class="o">=</span> <span class="n">data_object</span><span class="p">[</span><span class="s">"Body"</span><span class="p">]</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="nb">type</span><span class="p">(</span><span class="n">data_body</span><span class="p">)</span> <span class="c1"># the data is bytes
</span>
<span class="c1"># read the bytes
</span><span class="n">data_stream</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">data_body</span><span class="p">)</span>

<span class="c1"># create a dataframe from the stream with read_csv
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_stream</span><span class="p">)</span>
</code></pre></div></div> <p><strong>TIP</strong>: Turning data to <em>RecordSet</em> format allows models to perform really fast, and it’s a requirement for all SageMaker build-in models. To do the conversion, do the following:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the data to a numpy array
</span><span class="n">train_data_np</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s">'float32'</span><span class="p">)</span>

<span class="c1"># use a PCA model example
</span><span class="n">formatted_data</span> <span class="o">=</span> <span class="n">pca_model</span><span class="o">.</span><span class="n">record_set</span><span class="p">(</span><span class="n">train_data_np</span><span class="p">)</span>

</code></pre></div></div> <p>The model data are saved as a <code class="language-plaintext highlighter-rouge">tar</code> file, so we need to get that file back from the S3 location stored, and unzip it:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_key</span> <span class="o">=</span> <span class="s">'path_to_the_model_output'</span>

<span class="c1"># download the model
</span><span class="n">boto3</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s">'s3'</span><span class="p">)</span><span class="o">.</span><span class="n">Bucket</span><span class="p">(</span><span class="n">bucket_name</span><span class="p">)</span><span class="o">.</span><span class="n">download_file</span><span class="p">(</span><span class="n">model_key</span><span class="p">,</span> <span class="s">'model.tar.gz'</span><span class="p">)</span>

<span class="c1"># unzip and rename
</span><span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s">'tar -zxvf model.tar.gz'</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s">'unzip my_model'</span><span class="p">)</span>

<span class="c1"># load model as ndarray
</span><span class="kn">import</span> <span class="nn">mxnet</span> <span class="k">as</span> <span class="n">mx</span> <span class="c1"># build-in sagemaker pkg
</span><span class="n">model_params</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">'my_model'</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">parameters</span>
</code></pre></div></div> <p>At some point, we might want to see which is the optimal number of components that explain most of the variance in the data. For example, to calculate the explained variance for the top 5 components, calculate s squared for <em>each</em> of the top 5 components, add those up and normalize by the sum of <em>all</em> squared s values, according to this formula:</p> <p>\begin{equation<em>} \frac{\sum_{5}^{ } s_n^2}{\sum s^2} \end{equation</em>}</p> <p>The corresponding python function is the following:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">explained_variance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">n_top_components</span><span class="p">):</span>
    <span class="s">'''Calculates the approx. data variance that n_top_components captures.
       :param s: A dataframe of singular values for top components; 
           the top value is in the last row.
       :param n_top_components: An integer, the number of top components to use.
       :return: The expected data variance covered by the n_top_components.'''</span>
    
    <span class="n">start_idx</span> <span class="o">=</span> <span class="n">N_COMPONENTS</span> <span class="o">-</span> <span class="n">n_top_components</span>  <span class="c1">## 33-3 = 30, for example
</span>    <span class="c1"># calculate approx variance
</span>    <span class="n">exp_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:,:])</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">exp_variance</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <p>Now do some trial and error with different number of components to find the higher percentage of variance explaining:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># test cell
</span><span class="n">n_top_components</span> <span class="o">=</span> <span class="mi">7</span> <span class="c1"># select a value for the number of top components
</span>
<span class="c1"># calculate the explained variance
</span><span class="n">exp_variance</span> <span class="o">=</span> <span class="n">explained_variance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">n_top_components</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Explained variance: '</span><span class="p">,</span> <span class="n">exp_variance</span><span class="p">)</span>
</code></pre></div></div> <p>We can now examine the makeup of each PCA component based on the weightings of the original features that are included in the component. Could be used in a feature selectino process:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="k">def</span> <span class="nf">display_component</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">features_list</span><span class="p">,</span> <span class="n">component_num</span><span class="p">,</span> <span class="n">n_weights</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    
    <span class="c1"># get index of component (last row - component_num)
</span>    <span class="n">row_idx</span> <span class="o">=</span> <span class="n">N_COMPONENTS</span><span class="o">-</span><span class="n">component_num</span>

    <span class="c1"># get the list of weights from a row in v, dataframe
</span>    <span class="n">v_1_row</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">row_idx</span><span class="p">]</span>
    <span class="n">v_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">v_1_row</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

    <span class="c1"># match weights to features in counties_scaled dataframe, using list comporehension
</span>    <span class="n">comps</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">v_1</span><span class="p">,</span> <span class="n">features_list</span><span class="p">)),</span> 
                         <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'weights'</span><span class="p">,</span> <span class="s">'features'</span><span class="p">])</span>

    <span class="c1"># we'll want to sort by the largest n_weights
</span>    <span class="c1"># weights can be neg/pos and we'll sort by magnitude
</span>    <span class="n">comps</span><span class="p">[</span><span class="s">'abs_weights'</span><span class="p">]</span><span class="o">=</span><span class="n">comps</span><span class="p">[</span><span class="s">'weights'</span><span class="p">]</span><span class="o">.</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">sorted_weight_data</span> <span class="o">=</span> <span class="n">comps</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'abs_weights'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n_weights</span><span class="p">)</span>

    <span class="c1"># display using seaborn
</span>    <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">sorted_weight_data</span><span class="p">,</span> 
                   <span class="n">x</span><span class="o">=</span><span class="s">"weights"</span><span class="p">,</span> 
                   <span class="n">y</span><span class="o">=</span><span class="s">"features"</span><span class="p">,</span> 
                   <span class="n">palette</span><span class="o">=</span><span class="s">"Blues_d"</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"PCA Component Makeup, Component #"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">component_num</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <p>Keep in mind that some of the data in certain categories (columns) for each component will be left out.</p> <p>You can now deploy and predict with <code class="language-plaintext highlighter-rouge">model.deploy()</code> and <code class="language-plaintext highlighter-rouge">model.predict()</code></p> <p>We would also need to transform the data in order to use k-means, based on the components we have for each feature. To do that, use the following function:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create dimensionality-reduced data
</span><span class="k">def</span> <span class="nf">create_transformed_df</span><span class="p">(</span><span class="n">train_pca</span><span class="p">,</span> <span class="n">counties_scaled</span><span class="p">,</span> <span class="n">n_top_components</span><span class="p">):</span>
    <span class="s">''' Return a dataframe of data points with component features. 
        The dataframe should be indexed by State-County and contain component values.
        :param train_pca: A list of pca training data, returned by a PCA model.
        :param counties_scaled: A dataframe of normalized, original features.
        :param n_top_components: An integer, the number of top components to use.
        :return: A dataframe, indexed by State-County, with n_top_component values as columns.        
     '''</span>
    <span class="c1"># create new dataframe to add data to
</span>    <span class="n">counties_transformed</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

    <span class="c1"># for each of our new, transformed data points
</span>    <span class="c1"># append the component values to the dataframe
</span>    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_pca</span><span class="p">:</span>
        <span class="c1"># get component values for each data point
</span>        <span class="n">components</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">label</span><span class="p">[</span><span class="s">'projection'</span><span class="p">]</span><span class="o">.</span><span class="n">float32_tensor</span><span class="o">.</span><span class="n">values</span>
        <span class="n">counties_transformed</span><span class="o">=</span><span class="n">counties_transformed</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="nb">list</span><span class="p">(</span><span class="n">components</span><span class="p">)])</span>

    <span class="c1"># index by county, just like counties_scaled
</span>    <span class="n">counties_transformed</span><span class="o">.</span><span class="n">index</span><span class="o">=</span><span class="n">counties_scaled</span><span class="o">.</span><span class="n">index</span>

    <span class="c1"># keep only the top n components
</span>    <span class="n">start_idx</span> <span class="o">=</span> <span class="n">N_COMPONENTS</span> <span class="o">-</span> <span class="n">n_top_components</span>
    <span class="n">counties_transformed</span> <span class="o">=</span> <span class="n">counties_transformed</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="n">start_idx</span><span class="p">:]</span>
    
    <span class="c1"># reverse columns, component order     
</span>    <span class="k">return</span> <span class="n">counties_transformed</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></div> <p>After your dataset is created, make sure you delete all endpoints. We are now ready to apply our dataset to k-means. k-means deployment is very similar to the pca model deployment above. Find more on how to deploy a k-means model with SageMaker in the notebook mentioned above.</p> <h1 id="sagemeker-as-a-tool--the-future-of-ml">SageMeker as a Tool &amp; The Future of ML</h1> <h2 id="deploying-custom-models">Deploying Custom Models</h2> <h2 id="time-series-forecasting">Time-series Forecasting</h2> <p>For linear models, we can use SageMaker’s <code class="language-plaintext highlighter-rouge">LinerLearner</code>. We can always calculate the precision, recal and total accuracy to evaluate our models. En example of a linear regression model with SageMaker is presented <a href="https://github.com/Punchyou/ML_SageMaker_Studies/blob/master/Payment_Fraud_Detection/Fraud_Detection_Solution.ipynb">here</a>.</p> <h3 id="deepar">DeepAR</h3> <p>A SageMeker build-in RNN model for predictive modeling for timeseries. We will use energy consumption data from kaggle to use tha model. The dataset used can be found <a href="wget https://s3.amazonaws.com/video.udacity-data.com/topher/2019/March/5c88a3f1_household-electric-power-consumption/household-electric-power-consumption.zip">here</a>. The data needs to be preprocessed.</p> <p>DeepAR expect JSON (dict) as data input, with the fields <em>start</em> (string in datetime index format that defines the starting date and time), <em>target</em> and <em>cat</em> (encoded €categorical). We need to upload the data to S3, as we did before.</p> <p>for the training, first we create an image, which we will eventually pass into the estimator:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sagemaker.amazon.amazon_estimator</span> <span class="kn">import</span> <span class="n">get_image_uri</span>

<span class="n">image_name</span> <span class="o">=</span> <span class="n">get_image_uri</span><span class="p">(</span><span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span><span class="o">.</span><span class="n">region_name</span><span class="p">,</span> <span class="c1"># get the region
</span>                           <span class="s">'forecasting-deepar'</span><span class="p">)</span> <span class="c1"># specify image
</span></code></pre></div></div> <p>After training, we create a <code class="language-plaintext highlighter-rouge">predictor</code> in a similar way. The response is JSON of predictions, organized in quantiles (0.1, 0.5 (mean), 0.9). We will need to decode the JSON data. Find full code example <a href="https://github.com/Punchyou/ML_SageMaker_Studies/blob/master/Time_Series_Forecasting/Energy_Consumption_Solution.ipynb">here</a>.</p> <h2 id="project-plagiarism-detector">Project: Plagiarism Detector</h2> <p>Sources:</p> <ol> <li><a href="https://github.com/Punchyou/ML_SageMaker_Studies/">ML Case Studies repo</a></li> </ol> <p>Check more on SageMaker <a href="https://github.com/aws/amazon-sagemaker-examples">here</a>.</p> </div> <div id="disqus_thread"></div> </article> <script> var disqus_config = function () { this.page.url = "/ai/2021/02/24/machine-learning-cases/"; /* Replace PAGE_URL with your page's canonical URL variable */ this.page.identifier = "/ai/2021/02/24/machine-learning-cases"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */ }; (function () { /* DON'T EDIT BELOW THIS LINE */ var d = document, s = d.createElement('script'); s.src = 'https://.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a> </noscript></div> </div> <!-- End of row--> <div class="row"> <div class="col-md-4"> <div class="card"> <div class="card-header"> About </div> <div class="card-body"> <!-- Your Bio --> <p class="author_bio"> Hello, My Name is Maria.</p> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Categories </div> <div class="card-body text-dark"> <div id="#guides"></div> <li class="tag-head"> <a href="/blog/categories/guides">guides</a> </li> <a name="guides"></a> <div id="#dataScience"></div> <li class="tag-head"> <a href="/blog/categories/dataScience">dataScience</a> </li> <a name="dataScience"></a> <div id="#devops"></div> <li class="tag-head"> <a href="/blog/categories/devops">devops</a> </li> <a name="devops"></a> <div id="#resources"></div> <li class="tag-head"> <a href="/blog/categories/resources">resources</a> </li> <a name="resources"></a> <div id="#AI"></div> <li class="tag-head"> <a href="/blog/categories/AI">AI</a> </li> <a name="AI"></a> </div> </div> </div> <div class="col-md-4"> <div class="card"> <div class="card-header">Useful Links </div> <div class="card-body text-dark"> <li > <a href="/about">About Me</a> </li> <li > <a href="/blog">Blog</a> </li> </div> </div> </div> </div> </div> </div> <footer> <p> Powered by<a href="https://github.com/sujaykundu777/devlopr-jekyll"> devlopr jekyll</a>. Hosted at <a href="https://pages.github.com">Github</a>. Subscribe via <a href=" /feed.xml ">RSS</a> </p> </footer> </div> <script> var options = { classname: 'my-class', id: 'my-id' }; var nanobar = new Nanobar( options ); nanobar.go( 30 ); nanobar.go( 76 ); nanobar.go(100); </script> <div hidden id="snipcart" data-api-key="Y2I1NTAyNWYtMTNkMy00ODg0LWE4NDItNTZhYzUxNzJkZTI5NjM3MDI4NTUzNzYyMjQ4NzU0"></div> <script src="https://cdn.snipcart.com/themes/v3.0.0-beta.3/default/snipcart.js" defer></script> <script src="/assets/js/mode-switcher.js"></script> </body> </html>
